{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/07/17 10:57:56 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 192.168.242.128 instead (on interface ens33)\n",
      "23/07/17 10:57:56 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/07/17 10:57:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/07/17 10:57:58 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"twitter_transformation\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.json(\"../../curso2/datalake/twitter_datascience\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------+------------+\n",
      "|                data|            includes|              meta|extract_date|\n",
      "+--------------------+--------------------+------------------+------------+\n",
      "|[{87, 43, 2023-07...|{[{2023-07-14T17:...|{1234567890abcdef}|  2023-07-14|\n",
      "|[{30, 83, 2023-07...|{[{2023-07-14T11:...|{1234567890abcdef}|  2023-07-14|\n",
      "|[{0, 12, 2023-07-...|{[{2023-07-14T06:...|              null|  2023-07-14|\n",
      "|[{87, 99, 2023-07...|{[{2023-07-16T17:...|{1234567890abcdef}|  2023-07-16|\n",
      "|[{16, 30, 2023-07...|{[{2023-07-16T17:...|              null|  2023-07-16|\n",
      "|[{76, 51, 2023-07...|{[{2023-07-13T06:...|{1234567890abcdef}|  2023-07-13|\n",
      "|[{32, 55, 2023-07...|{[{2023-07-13T15:...|              null|  2023-07-13|\n",
      "|[{90, 5, 2023-07-...|{[{2023-07-15T20:...|              null|  2023-07-15|\n",
      "|[{16, 65, 2023-07...|{[{2023-07-12T14:...|              null|  2023-07-12|\n",
      "|[{57, 89, 2023-07...|{[{2023-07-11T06:...|              null|  2023-07-11|\n",
      "+--------------------+--------------------+------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- data: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- author_id: string (nullable = true)\n",
      " |    |    |-- conversation_id: string (nullable = true)\n",
      " |    |    |-- created_at: string (nullable = true)\n",
      " |    |    |-- edit_history_tweet_ids: array (nullable = true)\n",
      " |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- in_reply_to_user_id: string (nullable = true)\n",
      " |    |    |-- lang: string (nullable = true)\n",
      " |    |    |-- public_metrics: struct (nullable = true)\n",
      " |    |    |    |-- like_count: long (nullable = true)\n",
      " |    |    |    |-- quote_count: long (nullable = true)\n",
      " |    |    |    |-- reply_count: long (nullable = true)\n",
      " |    |    |    |-- retweet_count: long (nullable = true)\n",
      " |    |    |-- text: string (nullable = true)\n",
      " |-- includes: struct (nullable = true)\n",
      " |    |-- users: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- created_at: string (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- username: string (nullable = true)\n",
      " |-- meta: struct (nullable = true)\n",
      " |    |-- next_token: string (nullable = true)\n",
      " |-- extract_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- col: struct (nullable = true)\n",
      " |    |-- created_at: string (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- username: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(f.explode(\"includes.users\")).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 col|\n",
      "+--------------------+\n",
      "|{2023-07-14T17:08...|\n",
      "|{2023-07-14T02:24...|\n",
      "|{2023-07-14T11:38...|\n",
      "|{2023-07-14T15:16...|\n",
      "|{2023-07-14T08:40...|\n",
      "|{2023-07-14T00:39...|\n",
      "|{2023-07-14T13:38...|\n",
      "|{2023-07-14T19:45...|\n",
      "|{2023-07-14T04:42...|\n",
      "|{2023-07-14T10:43...|\n",
      "|{2023-07-14T11:36...|\n",
      "|{2023-07-14T04:26...|\n",
      "|{2023-07-14T18:00...|\n",
      "|{2023-07-14T20:46...|\n",
      "|{2023-07-14T10:40...|\n",
      "|{2023-07-14T22:58...|\n",
      "|{2023-07-14T04:02...|\n",
      "|{2023-07-14T14:08...|\n",
      "|{2023-07-14T16:16...|\n",
      "|{2023-07-14T16:24...|\n",
      "|{2023-07-14T06:03...|\n",
      "|{2023-07-14T19:13...|\n",
      "|{2023-07-14T23:27...|\n",
      "|{2023-07-14T23:04...|\n",
      "|{2023-07-14T08:29...|\n",
      "|{2023-07-14T12:25...|\n",
      "|{2023-07-14T13:22...|\n",
      "|{2023-07-14T21:52...|\n",
      "|{2023-07-14T06:04...|\n",
      "|{2023-07-14T18:50...|\n",
      "|{2023-07-16T17:57...|\n",
      "|{2023-07-16T04:41...|\n",
      "|{2023-07-16T07:48...|\n",
      "|{2023-07-16T05:25...|\n",
      "|{2023-07-16T08:38...|\n",
      "|{2023-07-16T08:55...|\n",
      "|{2023-07-16T02:18...|\n",
      "|{2023-07-16T05:44...|\n",
      "|{2023-07-16T16:39...|\n",
      "|{2023-07-16T04:46...|\n",
      "|{2023-07-16T17:04...|\n",
      "|{2023-07-16T14:07...|\n",
      "|{2023-07-16T03:42...|\n",
      "|{2023-07-16T03:59...|\n",
      "|{2023-07-16T15:51...|\n",
      "|{2023-07-16T08:08...|\n",
      "|{2023-07-16T21:54...|\n",
      "|{2023-07-16T16:43...|\n",
      "|{2023-07-16T01:42...|\n",
      "|{2023-07-16T09:41...|\n",
      "|{2023-07-13T06:30...|\n",
      "|{2023-07-13T22:46...|\n",
      "|{2023-07-13T09:40...|\n",
      "|{2023-07-13T01:03...|\n",
      "|{2023-07-13T11:45...|\n",
      "|{2023-07-13T12:58...|\n",
      "|{2023-07-13T01:52...|\n",
      "|{2023-07-13T00:12...|\n",
      "|{2023-07-13T06:36...|\n",
      "|{2023-07-13T20:48...|\n",
      "|{2023-07-13T15:04...|\n",
      "|{2023-07-13T08:13...|\n",
      "|{2023-07-13T05:40...|\n",
      "|{2023-07-13T01:10...|\n",
      "|{2023-07-13T08:53...|\n",
      "|{2023-07-13T21:41...|\n",
      "|{2023-07-13T16:17...|\n",
      "|{2023-07-13T06:46...|\n",
      "|{2023-07-13T04:33...|\n",
      "|{2023-07-13T02:39...|\n",
      "|{2023-07-15T20:15...|\n",
      "|{2023-07-15T06:38...|\n",
      "|{2023-07-15T23:44...|\n",
      "|{2023-07-15T05:38...|\n",
      "|{2023-07-15T07:48...|\n",
      "|{2023-07-15T13:57...|\n",
      "|{2023-07-15T17:24...|\n",
      "|{2023-07-15T22:26...|\n",
      "|{2023-07-15T06:07...|\n",
      "|{2023-07-15T04:12...|\n",
      "|{2023-07-12T14:25...|\n",
      "|{2023-07-12T18:49...|\n",
      "|{2023-07-12T16:50...|\n",
      "|{2023-07-12T05:39...|\n",
      "|{2023-07-12T05:26...|\n",
      "|{2023-07-12T16:19...|\n",
      "|{2023-07-12T14:17...|\n",
      "|{2023-07-12T18:12...|\n",
      "|{2023-07-12T08:05...|\n",
      "|{2023-07-12T02:47...|\n",
      "|{2023-07-11T06:51...|\n",
      "|{2023-07-11T04:23...|\n",
      "|{2023-07-11T14:33...|\n",
      "|{2023-07-11T04:42...|\n",
      "|{2023-07-11T14:23...|\n",
      "|{2023-07-11T11:25...|\n",
      "|{2023-07-11T16:52...|\n",
      "|{2023-07-11T12:37...|\n",
      "|{2023-07-11T18:21...|\n",
      "|{2023-07-11T11:36...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(f.explode(\"includes.users\")).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(f.explode(\"includes.users\").alias(\"users\")).select(\"users.*\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = df.select(f.explode(\"includes.users\").alias(\"users\")).select(\"users.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+------+--------+\n",
      "|          created_at| id|  name|username|\n",
      "+--------------------+---+------+--------+\n",
      "|2023-07-14T17:08:...| 11|User 1|   user1|\n",
      "|2023-07-14T02:24:...| 52|User 2|   user2|\n",
      "|2023-07-14T11:38:...| 93|User 3|   user3|\n",
      "|2023-07-14T15:16:...|  3|User 4|   user4|\n",
      "|2023-07-14T08:40:...| 24|User 5|   user5|\n",
      "+--------------------+---+------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.coalesce(1).write.mode(\"overwrite\").json('output/user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
